{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNaumhxe1d6JdTgzYmFGK5O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChiaraVanderputten/lab02DS/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp5FlA-HdQBA"
      },
      "source": [
        "# 1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_li76aYRglHl"
      },
      "source": [
        "from random import gauss\n",
        "import matplotlib.pyplot as plt\n",
        "l = [gauss(0, 1) for _ in range(500)]\n",
        "plt.hist(l)\n",
        "plt.title('Gaussian distribution (mu=0, sigma=1)')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIYqaBylgqnB"
      },
      "source": [
        "# 2.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp3lfMvbiO3F"
      },
      "source": [
        "! wget \"https://raw.githubusercontent.com/dbdmg/data-science-lab/master/datasets/GLT_filtered.csv\" -O GLT.csv\n",
        "\n",
        "import csv\n",
        "from numpy import mean\n",
        "\n",
        "col_name = []\n",
        "ds=[[],[],[],[],[],[],[]]\n",
        "\n",
        "with open(\"GLT.csv\") as f:\n",
        "  reader = csv.reader(f)\n",
        "  col_name = next(reader) #intrappoliamo qua la prima riga\n",
        "  for row in reader:\n",
        "    if len(row)==7:\n",
        "     for i in range(7):\n",
        "      ds[i].append(row[i])\n",
        "\n",
        "\n",
        "print(type(ds[1][2])) \n",
        "\n",
        "# DATI: \n",
        "# Date  nominale discreta?\n",
        "# AverageTemperature continuo\n",
        "# AverageTemperatureUncertainty continuo\n",
        "# City nominale\n",
        "# Country nominale\n",
        "# Latitude continua?\n",
        "# Longitude continua?\n",
        "\n",
        "def riempi(temp, citta):\n",
        "\n",
        " temp_des=0\n",
        " destra_vuoto=0\n",
        "\n",
        "  #mi salvo i valori che stanno a destra e a sinistra\n",
        " for i in range(len(temp)-1):\n",
        "   if i==0 or citta[i]!=citta[i-1]:\n",
        "     temp_sin=0\n",
        "   else:\n",
        "     temp_sin=float(temp[i-1])\n",
        "\n",
        "   if i < destra_vuoto:  #se ho più spazi vuoti vicini\n",
        "    temp[i]=float(temp_sin + temp_des)/2\n",
        "\n",
        "   if temp[i]=='':\n",
        "     for j in (i+1, len(temp)-1):\n",
        "       if i==len(temp)-1 or citta[j]!= citta[i]:\n",
        "         temp_des=0\n",
        "         break\n",
        "       elif temp[j]=='':\n",
        "         temp_des= float(temp[j]) #mi si crea un problema perchè se il valore a destra è vuoto non può essere salvato nel float\n",
        "         break\n",
        "\n",
        "     destra_vuoto=j\n",
        "     temp[i]= float(temp_des+temp_sin)/2\n",
        "   \n",
        "   else:\n",
        "     temp[i]= float(temp[i])\n",
        "\n",
        "\n",
        "l = ['', '12', '',  '', '', '15', ''] #errore\n",
        "c = ['Rome', 'Rome', 'Rome', 'Turin', 'Turin', 'Turin', 'Turin']\n",
        "\n",
        "print('Original list:', l)\n",
        "riempi(l, c)\n",
        "print('Filled list:', l)\n",
        "\n",
        "def tempPerCitta(citta):\n",
        " Temp_Citta=[]\n",
        " for i in range(len(ds[3])-1):\n",
        "   if ds[3][i]== citta and ds[1][i]!='':\n",
        "     Temp_Citta.append(float(ds[1][i]))\n",
        " return Temp_Citta\n",
        "  \n",
        "\n",
        "def topN(citta, N):\n",
        " lista = sorted(tempPerCitta(citta))\n",
        " print(f'Temperature più fredde per {citta}: ', lista[:N])\n",
        " print(f'Temperature più calde per {citta}: ', lista[-1:-(N+1):-1])\n",
        " #print(f'Lista ', lista)\n",
        "\n",
        "topN('Rome',5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P6iT1-UuLJB"
      },
      "source": [
        "# 2.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "3_swqu3WuSq4",
        "outputId": "5e0029f9-3390-41d4-9b78-96d0b0f25d41"
      },
      "source": [
        "! wget \"https://raw.githubusercontent.com/dbdmg/data-science-lab/master/datasets/aclimdb_reviews_train.txt\"\n",
        "from collections import Counter\n",
        "import csv\n",
        "recensioni=[]\n",
        "voti=[]\n",
        "with open(\"aclimdb_reviews_train.txt\", encoding='utf-8') as f:\n",
        "  reader = csv.reader(f)\n",
        "  next(reader) # salto la prima rig\n",
        "  for row in reader:\n",
        "        recensioni.append(row[0])\n",
        "        voti.append(row[1]) \n",
        "\n",
        "#print(voti) \n",
        "import math\n",
        "import string\n",
        "def tokenize(docs):\n",
        "#Compute the tokens for each document.\n",
        "#Input: a list of strings. Each item is a document to tokenize.\n",
        "#Output: a list of lists. Each item is a list containing the tokens of the\n",
        "#relative document.\n",
        " tokens = []\n",
        " for doc in docs:\n",
        "  for punct in string.punctuation:\n",
        "   doc = doc.replace(punct, \" \")\n",
        "  split_doc = [ token.lower() for token in doc.split(\" \") if token ]\n",
        "  tokens.append(split_doc)\n",
        " return tokens\n",
        "\n",
        "tok={}\n",
        "tok=tokenize(recensioni)\n",
        "#print(tokenize(recensioni)[0])\n",
        "\n",
        "def contatore_token(document):\n",
        "  #creo una mappa in cui la chiave è il token che si ripete e il valore è il numero di volte che si ripete\n",
        " mappa={} \n",
        " for i in range(len(document)):\n",
        "   if document[i] not in mappa:\n",
        "     mappa[document[i]] = 1\n",
        "   else:\n",
        "    mappa[document[i]] = mappa[document[i]]+1 \n",
        " print(mappa)\n",
        "\n",
        "#contatore_token(tokenize(recensioni)[0])\n",
        "\n",
        "def IDF (documenti):\n",
        "  N = len(documenti)\n",
        "  mappaDF={}\n",
        "  mappaIDF={}\n",
        "\n",
        "  for recensioni in documenti: #per tutte le recensioni\n",
        "    for token in contatore_token(recensioni).items(): #per tutti i token della recensione\n",
        "     if token in mappaDF: #se la mappa contiene già quel token ne incremento di uno il valore\n",
        "      mappaDF[token] = mappaDF[token]+1\n",
        "     else:                 #altrimenti lo aggiungo con valore 1\n",
        "       mappaDF[token] = 1\n",
        "\n",
        "  for tok , cont in mappaDF.items():\n",
        "    mappaIDF[tok] = math.log(N/cont)\n",
        "  return mappaIDF\n",
        "\n",
        "print(IDF(tok))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-02 11:54:37--  https://raw.githubusercontent.com/dbdmg/data-science-lab/master/datasets/aclimdb_reviews_train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33322169 (32M) [text/plain]\n",
            "Saving to: ‘aclimdb_reviews_train.txt.11’\n",
            "\n",
            "aclimdb_reviews_tra 100%[===================>]  31.78M   179MB/s    in 0.2s    \n",
            "\n",
            "2021-11-02 11:54:38 (179 MB/s) - ‘aclimdb_reviews_train.txt.11’ saved [33322169/33322169]\n",
            "\n",
            "{'for': 3, 'a': 5, 'movie': 2, 'that': 1, 'gets': 1, 'no': 1, 'respect': 1, 'there': 1, 'sure': 1, 'are': 1, 'lot': 1, 'of': 1, 'memorable': 1, 'quotes': 1, 'listed': 1, 'this': 1, 'gem': 1, 'imagine': 1, 'where': 1, 'joe': 1, 'piscopo': 1, 'is': 3, 'actually': 1, 'funny': 1, 'maureen': 1, 'stapleton': 1, 'scene': 1, 'stealer': 1, 'the': 2, 'moroni': 1, 'character': 1, 'an': 1, 'absolute': 1, 'scream': 1, 'watch': 1, 'alan': 1, 'skipper': 1, 'hale': 1, 'jr': 1, 'as': 1, 'police': 1, 'sgt': 1}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-1fec889f096e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmappaIDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-1fec889f096e>\u001b[0m in \u001b[0;36mIDF\u001b[0;34m(documenti)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mrecensioni\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocumenti\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#per tutte le recensioni\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontatore_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecensioni\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#per tutti i token della recensione\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmappaDF\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#se la mappa contiene già quel token ne incremento di uno il valore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mmappaDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmappaDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
          ]
        }
      ]
    }
  ]
}